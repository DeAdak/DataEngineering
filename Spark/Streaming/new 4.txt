SparkSession spark = SparkSession.builder().appName("SparkCassandraApp").config("spark.cassandra.connection.host", "localhost").config("spark.cassandra.connection.port", "9042").master("local[2]").getOrCreate()

CassandraConnector connector = CassandraConnector.apply(spark.sparkContext().conf());
Session session = connector.openSession();
session.execute("select * first_tab.relative");

import org.apache.spark.SparkSession
val spark = new SparkSession.builder.appName("SparkCassandraApp").config("spark.cassandra.connection.host", "localhost").config("spark.cassandra.connection.port", "9042").master("local").getOrCreate()

spark.read.fo

pyspark --packages com.datastax.spark:spark-cassandra-connector_2.11:2.5.2
--------------------------------------------
import org.apache.spark.sql.cassandra._
import com.datastax.spark.connector._
import com.datastax.spark.connector.cql.CassandraConnector

//if using Spark 2.x, CosmosDB library for multiple retry
//import com.microsoft.azure.cosmosdb.cassandra

val readBooksDF = spark.read.format("org.apache.spark.sql.cassandra").options(Map( "table" -> "relative", "keyspace" -> "first_tab")).load

readBooksDF.explain
readBooksDF.show

val readBooksDF = spark.read.format("org.apache.spark.sql.cassandra").options(Map( "table" -> "books", "keyspace" -> "books_ks")).load
 